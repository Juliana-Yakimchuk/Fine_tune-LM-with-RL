# Fine_tune-LM-with-RL

#### -- Project Status: [Active]

## Project Intro/Objective
The purpose of this project is fine-tuning an abstractive text summarization model using transfer learning and reinforcement learning. RL is one of the most promising and computationally efficient methods of fine-tuning language models and is in a active research area.

### Methods Used
* EDA
* Deep Learning
* Reinforcement Learning

### Technologies
* Python
* Jupyter Notebooks


## Needs of this project

- data exploration
- data processing/cleaning - stop word removal/tokenization/lemmatization
- transfer learning - reusing a pertained LM
- reinforcement fine-tuning - setting up a RL agent architecture, reward model, and cost function consisting of two elements
 - if time permits, adding a supervised fine-tuning elect, as research shows a combination of supervised and RL fine-tuning is most efficient.
- writeup/reporting

## Getting Started

1. Clone this repo (for help see this [tutorial](https://help.github.com/articles/cloning-a-repository/)).
2. Raw Data could be loaded from HuggingFace library and code to load it is part of the notebook 
    
